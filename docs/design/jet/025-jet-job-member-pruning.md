# Jet job member pruning

|||
|---|---|
|Related Jira|[HZ-1605](https://hazelcast.atlassian.net/browse/HZ-1605)|
|Document Status / Completeness|IN PROGRESS|
|Requirement owner|Sandeep Akhouri|
|Developer(s)|Sasha Syrotenko|
|Quality Engineer|Isaac Sumner|
|Technical Reviewers|TBD|
|Version|5.4|

## Background

Before Hazelcast Platform 5.4, Jet job was always deployed to all data members. If some DAG vertex isn’t using all 
members, it creates no-op processors on the rest, but the system still creates queues to/from those vertices
and starts the processors, even though it completes immediately and the queues are closed with a `DONE_ITEM`. 
If some member isn’t used at all, the DAG is still deployed to it, and the master has to send it to it and wait 
for the completion. Even though the processors are no-op, or have no data to process, it’s an unnecessary overhead, 
which becomes noticeable in very small batch jobs.

## Terminology


## Goals

- deploy a job only on members with required partitions on them
- 

Non-goals are :
- support member pruning for streaming jobs. 
- support migration-tolerance for member pruning. 


## Technical Design

As it was mentioned in Background section

First, we propose changing the contract of `ProcessorMetaSupplier#get` return function so that it will be
allowed to return `null` for addresses for which it does not want to deploy processors. But this will not be enough 
to completely eliminate a member from the execution. 

Consider this DAG for example:
p1 -> p2
The `p1` is the source, and `p2` is the sink, but we deliberately don't use that term, because the processor logic is
opaque to Jet. If `p1` is null for a member, `p2` has no input. But `p2` is still allowed to generate data, 
so we can’t eliminate it. For example, if `p2` outputs the sum of input items, it still might want to emit `0`, 
if there’s no input. 

To support this behaviour, we need to extend the API. One option is add a method to PMS:
```java
interface ProcessorMetaSupplier extends IdentifiedDataSerializable {
    // ...
    default boolean doesWorkWithoutInput() {
        return true;
    }
    // ...
}
```
The default return value is `true` for backwards compatibility. This means that all current and new processors that 
do no work without an input will have to override this method.

Second, we need to support that solution in `ExecutionPlanBuilder` (execution plan creation phase). 
Previous `ProcessorMetaSupplier#get` contract was a reason for strict assumptions in execution plan creation algorithm, 
but that has changed. Moreover, we need to change algorithm in `ExecutionPlanBuilder` to accept `nulls`, and this is way
trickier part to solve.

There are two main approaches were considered, to shorten their meaning we mark them as 'heavyweight' and 'lightweight'.
Long story short, the difference between these two approaches is an exact stage when we understand that some member
may be pruned from job execution: 'heavyweight' approach tries to be more generic and define it for any accept DAG, when
'lightweight' approach focus on hinting `ExecutionPlanBuilder` with additional metainformation from DAG and JobConfig 
constructed by SQL optimizer.

More details are available in chapters below.

#### Heavyweight approach

The core idea of that approach is that  `ExecutionPlanBuilder` would have detailed analysis of received DAG before 
execution plan creation and then, possibly, trying to optimize DAG and only then apply member pruning based. Here, the
requirements to prune member are : 
- each vertex in the DAG may work without an input;
- DAG does not contain `distributed-broadcast` edges; 
- even if DAG contains `distributed-broadcast` edges, do they have any  ; 
As a pros, using this approach generify member pruning usage for both SQL and Pipeline API. 
As a cons, this approach brings high complexity in problem analysis, long development and big list of corner cases, which
are discussed in chapter below.

##### Issues/corner cases for heavyweight approach.
Note : to be written. Maybe author will involve ASCII art for better visibility.

1. Source -> Transform -> Aggregation -> Sink.
Edges to Aggregation vertex (as a rule)  may be distributed.

#### Lightweight approach

Unlike a way described above, we can think that member pruning would be beneficial mostly for small jobs. 
The overwhelming majority of such jobs are generated by SQL, and our team effort is to replace Predicate API, 
where `PartitionPredicate` is available for collocated data querying. 
For that, we can use SQL optimization phase also for determining partitions and members which contains 
requested partitions for all relations (and later vertexes in DAG) : we would extract information 
about requried partitions to run to JobConfig, (possibly mark DAG as 

##### Issues/corner cases for lightweight approach.

1. Any SELECT queries may require a coordinator member to participate in job as sink result consumer. 

### Notes


































